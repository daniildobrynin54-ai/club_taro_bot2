"""
–ü–∞—Ä—Å–µ—Ä –¥–∞–Ω–Ω—ã—Ö –∏–∑ Google Sheets –¥–ª—è –ø—Ä–æ—Ñ–∏–ª–µ–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π
‚úÖ –ò–°–ü–†–ê–í–õ–ï–ù–û: –ü—Ä–∞–≤–∏–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ UTF-8 –∫–æ–¥–∏—Ä–æ–≤–∫–∏
‚úÖ –û–ë–ù–û–í–õ–ï–ù–û: –í—Å–µ –¥–∞–Ω–Ω—ã–µ —Ç–µ–ø–µ—Ä—å –±–µ—Ä—É—Ç—Å—è —Å –ª–∏—Å—Ç–∞ –∏–Ω–≤–µ–Ω—Ç–∞—Ä—è
"""
import logging
import csv
import requests
from typing import Optional, Dict
from io import StringIO

logger = logging.getLogger(__name__)

# ID —Ç–∞–±–ª–∏—Ü—ã –∏ –ª–∏—Å—Ç–æ–≤
SPREADSHEET_ID = "1sYvrBU9BPhcoxTnNJfx8TOutxwFrSiRm2mw_8s6rdZM"
MAIN_SHEET_GID = "846561775"  # –û—Å–Ω–æ–≤–Ω–æ–π –ª–∏—Å—Ç (–¥–ª—è –±–∞–ª–∞–Ω—Å–∞ –∏ –≤–∫–ª–∞–¥–∞)
INVENTORY_SHEET_GID = "1142214254"  # –õ–∏—Å—Ç –∏–Ω–≤–µ–Ω—Ç–∞—Ä—è (–¥–ª—è –∞—Ä–∫–∞–Ω—ã, –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏, –∏–Ω–≤–µ–Ω—Ç–∞—Ä—è)

# URL –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞ –≤ CSV
MAIN_SHEET_URL = f"https://docs.google.com/spreadsheets/d/{SPREADSHEET_ID}/export?format=csv&gid={MAIN_SHEET_GID}"
INVENTORY_SHEET_URL = f"https://docs.google.com/spreadsheets/d/{SPREADSHEET_ID}/export?format=csv&gid={INVENTORY_SHEET_GID}"


class SheetsParser:
    """–ü–∞—Ä—Å–µ—Ä –¥–∞–Ω–Ω—ã—Ö –∏–∑ Google Sheets"""
    
    def __init__(self):
        self.main_data_cache = None
        self.inventory_data_cache = None
    
    def _download_sheet(self, url: str) -> Optional[list]:
        """
        –°–∫–∞—á–∏–≤–∞–µ—Ç –∏ –ø–∞—Ä—Å–∏—Ç Google Sheet –∫–∞–∫ CSV
        ‚úÖ –ò–°–ü–†–ê–í–õ–ï–ù–û: –ü—Ä–∞–≤–∏–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ UTF-8
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ —Å—Ç—Ä–æ–∫ (–∫–∞–∂–¥–∞—è —Å—Ç—Ä–æ–∫–∞ - —Å–ø–∏—Å–æ–∫ –∑–Ω–∞—á–µ–Ω–∏–π)
        """
        try:
            logger.debug(f"–ó–∞–≥—Ä—É–∑–∫–∞ —Ç–∞–±–ª–∏—Ü—ã: {url}")
            response = requests.get(url, timeout=30)
            
            if response.status_code != 200:
                logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Ç–∞–±–ª–∏—Ü—ã: {response.status_code}")
                return None
            
            # ‚úÖ –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –Ø–≤–Ω–æ —É–∫–∞–∑—ã–≤–∞–µ–º UTF-8 –∫–æ–¥–∏—Ä–æ–≤–∫—É
            response.encoding = 'utf-8'
            
            # –ü–∞—Ä—Å–∏–º CSV —Å UTF-8
            csv_data = StringIO(response.text)
            reader = csv.reader(csv_data)
            rows = list(reader)
            
            logger.info(f"‚úÖ –¢–∞–±–ª–∏—Ü–∞ –∑–∞–≥—Ä—É–∂–µ–Ω–∞: {len(rows)} —Å—Ç—Ä–æ–∫")
            return rows
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Ç–∞–±–ª–∏—Ü—ã: {e}")
            return None
    
    def _column_letter_to_index(self, letter: str) -> int:
        """–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç –±—É–∫–≤—É –∫–æ–ª–æ–Ω–∫–∏ –≤ –∏–Ω–¥–µ–∫—Å (A=0, B=1, ..., Z=25, AA=26)"""
        result = 0
        for char in letter.upper():
            result = result * 26 + (ord(char) - ord('A') + 1)
        return result - 1
    
    def get_user_inventory_data(self, profile_url: str, force_refresh: bool = False) -> Optional[Dict]:
        """
        ‚úÖ –û–ë–ù–û–í–õ–ï–ù–û: –ü–æ–ª—É—á–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ —Å –ª–∏—Å—Ç–∞ –∏–Ω–≤–µ–Ω—Ç–∞—Ä—è
        
        –¢–µ–ø–µ—Ä—å –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç:
        {
            'arcana': str,           # –°—Ç–æ–ª–±–µ—Ü D
            'sequence': str,         # –°—Ç–æ–ª–±–µ—Ü H
            'sequence_number': str,  # –°—Ç–æ–ª–±–µ—Ü G
            'inventory': str,        # –°—Ç–æ–ª–±–µ—Ü J
        }
        """
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
        if self.inventory_data_cache is None or force_refresh:
            self.inventory_data_cache = self._download_sheet(INVENTORY_SHEET_URL)
        
        if not self.inventory_data_cache:
            logger.error("–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –ª–∏—Å—Ç –∏–Ω–≤–µ–Ω—Ç–∞—Ä—è")
            return None
        
        # –ò–Ω–¥–µ–∫—Å—ã —Å—Ç–æ–ª–±—Ü–æ–≤ (A=0, B=1, C=2, ...)
        COL_A = 0   # Profile URL
        COL_D = 3   # ‚úÖ –ê—Ä–∫–∞–Ω–∞
        COL_G = 6   # ‚úÖ –ù–æ–º–µ—Ä –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ (–≤ —Å–∫–æ–±–∫–∞—Ö)
        COL_H = 7   # ‚úÖ –ü–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å (–Ω–∞–∑–≤–∞–Ω–∏–µ)
        COL_J = 9   # –ò–Ω–≤–µ–Ω—Ç–∞—Ä—å
        
        # –ò—â–µ–º —Å—Ç—Ä–æ–∫—É —Å —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ–º –ø–æ profile_url
        for row_idx, row in enumerate(self.inventory_data_cache):
            # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫
            if row_idx == 0:
                continue
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –ª–∏ –∫–æ–ª–æ–Ω–æ–∫
            if len(row) <= COL_A:
                continue
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ URL (—Å—Ç–æ–ª–±–µ—Ü A)
            if row[COL_A].strip() == profile_url.strip():
                logger.info(f"‚úÖ –ù–∞–π–¥–µ–Ω –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –≤ –ª–∏—Å—Ç–µ –∏–Ω–≤–µ–Ω—Ç–∞—Ä—è: —Å—Ç—Ä–æ–∫–∞ {row_idx + 1}")
                
                return {
                    'arcana': row[COL_D].strip() if len(row) > COL_D else '',
                    'sequence': row[COL_H].strip() if len(row) > COL_H else '',
                    'sequence_number': row[COL_G].strip() if len(row) > COL_G else '',
                    'inventory': row[COL_J].strip() if len(row) > COL_J else '',
                }
        
        logger.warning(f"‚ö†Ô∏è –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –ª–∏—Å—Ç–µ –∏–Ω–≤–µ–Ω—Ç–∞—Ä—è: {profile_url}")
        return None
    
    def get_user_main_data(self, profile_url: str, force_refresh: bool = False) -> Optional[Dict]:
        """
        ‚úÖ –û–ë–ù–û–í–õ–ï–ù–û: –ü–æ–ª—É—á–∞–µ—Ç —Ç–æ–ª—å–∫–æ –±–∞–ª–∞–Ω—Å –∏ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –≤–∫–ª–∞–¥–∞ —Å –æ—Å–Ω–æ–≤–Ω–æ–≥–æ –ª–∏—Å—Ç–∞
        
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:
        {
            'balance': str,          # –°—Ç–æ–ª–±–µ—Ü P
            'column_l': str,         # –°—Ç–æ–ª–±–µ—Ü L (–¥–ª—è —Ä–∞—Å—á–µ—Ç–∞ –≤–∫–ª–∞–¥–∞)
            'column_j': str,         # –°—Ç–æ–ª–±–µ—Ü J (–¥–ª—è —Ä–∞—Å—á–µ—Ç–∞ –≤–∫–ª–∞–¥–∞)
        }
        """
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
        if self.main_data_cache is None or force_refresh:
            self.main_data_cache = self._download_sheet(MAIN_SHEET_URL)
        
        if not self.main_data_cache:
            logger.error("–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –æ—Å–Ω–æ–≤–Ω–æ–π –ª–∏—Å—Ç")
            return None
        
        # –ò–Ω–¥–µ–∫—Å—ã —Å—Ç–æ–ª–±—Ü–æ–≤ (A=0, B=1, C=2, ...)
        COL_B = 1   # Profile URL
        COL_J = 9   # J (–¥–ª—è –≤–∫–ª–∞–¥–∞)
        COL_L = 11  # L (–¥–ª—è –≤–∫–ª–∞–¥–∞)
        COL_P = 15  # –ë–∞–ª–∞–Ω—Å –û–ö
        
        # –ò—â–µ–º —Å—Ç—Ä–æ–∫—É —Å —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ–º –ø–æ profile_url
        for row_idx, row in enumerate(self.main_data_cache):
            # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫
            if row_idx == 0:
                continue
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –ª–∏ –∫–æ–ª–æ–Ω–æ–∫
            if len(row) <= COL_B:
                continue
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ URL (—Å—Ç–æ–ª–±–µ—Ü B)
            if row[COL_B].strip() == profile_url.strip():
                logger.info(f"‚úÖ –ù–∞–π–¥–µ–Ω –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –≤ –æ—Å–Ω–æ–≤–Ω–æ–º –ª–∏—Å—Ç–µ: —Å—Ç—Ä–æ–∫–∞ {row_idx + 1}")
                
                return {
                    'balance': row[COL_P].strip() if len(row) > COL_P else '0',
                    'column_l': row[COL_L].strip() if len(row) > COL_L else '0',
                    'column_j': row[COL_J].strip() if len(row) > COL_J else '0',
                }
        
        logger.warning(f"‚ö†Ô∏è –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –æ—Å–Ω–æ–≤–Ω–æ–º –ª–∏—Å—Ç–µ: {profile_url}")
        return None
    
    def clear_cache(self):
        """–û—á–∏—â–∞–µ—Ç –∫–µ—à –¥–∞–Ω–Ω—ã—Ö (–¥–ª—è –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ–≥–æ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è)"""
        self.main_data_cache = None
        self.inventory_data_cache = None
        logger.info("üóëÔ∏è –ö–µ—à —Ç–∞–±–ª–∏—Ü –æ—á–∏—â–µ–Ω")


# –ì–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä –ø–∞—Ä—Å–µ—Ä–∞
_parser_instance = None


def get_sheets_parser() -> SheetsParser:
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –≥–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä –ø–∞—Ä—Å–µ—Ä–∞"""
    global _parser_instance
    if _parser_instance is None:
        _parser_instance = SheetsParser()
    return _parser_instance